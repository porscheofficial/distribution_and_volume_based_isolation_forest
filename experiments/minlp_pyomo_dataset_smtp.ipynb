{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os, sys\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (15,7)\n",
    "\n",
    "CURRENT_DIR = os.path.dirname(os.path.abspath(\"rare_pattern_detect\"))\n",
    "sys.path.append(os.path.dirname(CURRENT_DIR))\n",
    "\n",
    "from rare_pattern_detect.patterns import PatternSpace, PatternSpaceType\n",
    "from rare_pattern_detect.rare_pattern_detect import RarePatternDetect\n",
    "from rare_pattern_detect.pattern_space_utils import draw_largest_bounding_area, draw2dpattern"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluating 20 data points (10 anomalies and 10 normal points) using 200 training points"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # Loading the data\n",
    "with np.load('../ADBench-main/datasets/Classical/34_smtp.npz') as data:\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "    idx = np.random.permutation(len(X))\n",
    "    X,y = X[idx], y[idx]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "anomalies_indices = [i for i, j in enumerate(y) if j == 1]\n",
    "\n",
    "normal_indices = [i for i, j in enumerate(y) if j != 1]\n",
    "\n",
    "print(\"anomalies_indices: \", len(anomalies_indices))\n",
    "\n",
    "print(\"normal_indices: \", len(normal_indices))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "TRAINING_LIMIT = 200\n",
    "TESTING_INDICES = -20 \n",
    "TRAINING_ANOMALIES_INDICES = 10 \n",
    "\n",
    "testing_anomalies_indices = anomalies_indices[TESTING_INDICES:]\n",
    "\n",
    "testing_normal_indices = normal_indices[TESTING_INDICES:]\n",
    "\n",
    "training_normal_indices = normal_indices[:TRAINING_LIMIT]\n",
    "\n",
    "training_anomalies_indices = anomalies_indices[:TRAINING_ANOMALIES_INDICES]\n",
    "\n",
    "testing_indices = np.concatenate((testing_anomalies_indices, testing_normal_indices))\n",
    "\n",
    "testing_labels = y[testing_indices]\n",
    "\n",
    "y = testing_labels"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# training_set = np.array(X[training_normal_indices])\n",
    "\n",
    "training_set = np.array(np.concatenate((X[training_normal_indices],X[training_anomalies_indices])))\n",
    "\n",
    "testing_set = np.array(np.concatenate((X[testing_anomalies_indices],X[testing_normal_indices])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3D scatter plot"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# training_set\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "sns.set(style = \"darkgrid\")\n",
    "\n",
    "def scatter_plot_3d(set, title):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection = '3d')\n",
    "\n",
    "    x = set[:,0]\n",
    "    y = set[:,1]\n",
    "    z = set[:,2]\n",
    "\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.set_zlabel(\"z\")\n",
    "    ax.scatter(x, y, z)\n",
    "    ax.set_title(f\"{title}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "scatter_plot_3d(training_set, \"training\")\n",
    "scatter_plot_3d(testing_set, \"testing\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def calculate_f_hats(training_set, testing_set, y, min_area):\n",
    "    initial_tau = 0.1\n",
    "    epsilon = 0.1\n",
    "    delta = 0.1\n",
    "\n",
    "    print(f\"num datapoints: {len(y)}\")\n",
    "\n",
    "\n",
    "    rpd = RarePatternDetect(\n",
    "        delta=delta,\n",
    "        tau=initial_tau,\n",
    "        epsilon=epsilon,\n",
    "        pattern_space = PatternSpace(\n",
    "            type = PatternSpaceType.AXIS_ALIGNED_HYPER_RECTANGLES, \n",
    "            cutoff = min_area\n",
    "        )\n",
    "    )\n",
    "\n",
    "    rpd.fit(training_data=training_set, testing_data=testing_set)\n",
    "    preds = []\n",
    "    f_hats = []\n",
    "    print(\"number of points to be classified: \", len(testing_set))\n",
    "    for i, point_to_be_classified in enumerate(testing_set):\n",
    "        # if i % 10 == 0: \n",
    "        print(f\"----- {i} data points processed -----\")\n",
    "        model, prediction = rpd.predict_score(point_to_be_classified)\n",
    "        preds.append(prediction)\n",
    "        f_hats.append(model.minimized_f_hats) # [i])\n",
    "\n",
    "    return f_hats\n",
    "\n",
    "def evaluate_fhat_distribution(f_hats, min_area):\n",
    "    ## Evaluating the f_hat distributions \n",
    "    indices = [i for i, j in enumerate(y) if j == 1]\n",
    "    fhat_anomelies = [f_hats[i] for i, j in enumerate(indices)]\n",
    "    fhat_normal = [j for i, j in enumerate(f_hats) if i not in indices]\n",
    "\n",
    "    sns.histplot(fhat_normal, label=y, color=\"green\")\n",
    "    sns.histplot(fhat_anomelies, label=y, color=\"blue\")\n",
    "    plt.legend(labels=[\"normal\",\"anormalies\"])\n",
    "    plt.title(f\"f_hat distribution for min_area:{min_area}\")\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# creating a range of taus\n",
    "taus = [0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.2, 0.5, 0.7, 1.0]  # , 2.0, 2.5, 3.0, 4.0]\n",
    "min_areas = [31, 35, 41] # [4.6, 10, 20, 30, 46]\n",
    "epsilon = 0.1\n",
    "pac_rpad_results = []\n",
    "\n",
    "for i, min_area in enumerate(min_areas):\n",
    "    print(\"iteration: \", i)\n",
    "\n",
    "    f_hats = calculate_f_hats(training_set, testing_set, y, min_area)\n",
    "    \n",
    "    evaluate_fhat_distribution(f_hats, min_area)\n",
    "\n",
    "    predictions_list = []\n",
    "\n",
    "    for i, tau in enumerate(taus):\n",
    "        print(f\"––– ––– ––– new round: i={i}, mu :{(tau + (epsilon/2))}  ––– ––– –––\")\n",
    "        \n",
    "        predictions = np.asarray(f_hats) < (tau + (epsilon/2))\n",
    "        predictions_list.append([tau + (epsilon/2), min_area, predictions])\n",
    "\n",
    "        preds = np.where(predictions==1, predictions, False).astype(bool)\n",
    "        count_similar_predictions = np.count_nonzero(y == preds)\n",
    "        per_similar_predictions = count_similar_predictions/len(y)\n",
    "        print(f\" correct results: {count_similar_predictions},  percentage: {per_similar_predictions}\")\n",
    "\n",
    "    pac_rpad_results.append(predictions_list)\n",
    "\n",
    "    for i, (mu,_,p) in enumerate(predictions_list):\n",
    "\n",
    "        auc = metrics.roc_auc_score(y, p)\n",
    "\n",
    "        # Recall that a model with an AUC score of 0.5 is no better than a model that performs random guessing.\n",
    "        print(\"auroc: \",auc)\n",
    "\n",
    "        fpr, tpr, _ = metrics.roc_curve(y, p)\n",
    "        \n",
    "        #create ROC curve\n",
    "        plt.plot(fpr,tpr, label=f\"mu: {np.round(mu, 3)}, auroc: {np.round(auc,3)}\")\n",
    "        plt.legend(loc=\"upper left\")\n",
    "\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pac_rpad_predictions = np.asarray(predictions_list, dtype=object)[:,2]\n",
    "\n",
    "# True -> anomalie || False -> normal point\n",
    "pac_rpad_converted_predictions = [x.astype('uint8') for _, x in enumerate(pac_rpad_predictions)]\n",
    "pac_rpad_converted_predictions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Comparison with IF"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "clf = IsolationForest(random_state=0).fit(training_set)\n",
    "\n",
    "# -1 anomalie\n",
    "r = clf.predict(testing_set) \n",
    "\n",
    "print(\"IF results: \", r)\n",
    "\n",
    "r = - np.where(r==-1, r, 0)\n",
    " \n",
    "print(\"converted IF results: \",r)\n",
    "\n",
    "# 1 -> anomalies. 0 -> normal\n",
    "print(\"true labels: \", y)\n",
    "\n",
    "count_similar_predictions = np.count_nonzero(r == y)\n",
    "per_similar_predictions = count_similar_predictions/len(testing_set)\n",
    "\n",
    "print(\"count_similar_predictions: \", count_similar_predictions)\n",
    "print(\"per_similar_predictions: \", per_similar_predictions)\n",
    "\n",
    "auc = metrics.roc_auc_score(y, r)\n",
    "\n",
    "print(\"auc: \", auc)\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(y, r)\n",
    "print(\"fpr, tpr: \", fpr, tpr)\n",
    "\n",
    "plt.plot(fpr,tpr);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "[np.count_nonzero(pac_rpad_pred == y) for _, pac_rpad_pred in enumerate(pac_rpad_converted_predictions)]"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.15 64-bit ('pac-venv')"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.15",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "4ede7f29d864d30436995b20b34666eece4fa61a1cdb58253be3ba6b07adb827"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}